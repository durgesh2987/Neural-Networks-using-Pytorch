{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_3_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durgesh2987/Neural-Networks-using-Pytorch/blob/master/Part_3_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7exC-3o-VFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwmJYtuOAX9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c05b195e-9f36-4621-becf-720441a7e1e7"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n",
            "tensor(2.3216, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x47XbEMsCg5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10e5f8be-a03b-44f6-f89a-d533a7075649"
      },
      "source": [
        "# Solution\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logps = model(images)\n",
        "\n",
        "# Calculate the loss with the logps and the labels\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2908, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQqjyqbRRAa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9xBCoDtkIAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2ffa85be-bfe2-476b-a58f-2a30b6f24503"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-4.0529e-04, -4.0529e-04, -4.0529e-04,  ..., -4.0529e-04,\n",
            "         -4.0529e-04, -4.0529e-04],\n",
            "        [ 1.3598e-03,  1.3598e-03,  1.3598e-03,  ...,  1.3598e-03,\n",
            "          1.3598e-03,  1.3598e-03],\n",
            "        [-5.9368e-04, -5.9368e-04, -5.9368e-04,  ..., -5.9368e-04,\n",
            "         -5.9368e-04, -5.9368e-04],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 4.1093e-06,  4.1093e-06,  4.1093e-06,  ...,  4.1093e-06,\n",
            "          4.1093e-06,  4.1093e-06],\n",
            "        [-9.4784e-04, -9.4784e-04, -9.4784e-04,  ..., -9.4784e-04,\n",
            "         -9.4784e-04, -9.4784e-04]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAvP_QjKv_XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RII0ft8LwFKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3fc6515b-6e0e-4b28-da03-4b6ec2cec232"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0207,  0.0028, -0.0034,  ..., -0.0145, -0.0312, -0.0174],\n",
            "        [ 0.0129,  0.0149,  0.0335,  ...,  0.0240,  0.0066, -0.0346],\n",
            "        [ 0.0346,  0.0130,  0.0321,  ...,  0.0087,  0.0297,  0.0203],\n",
            "        ...,\n",
            "        [-0.0032,  0.0189,  0.0192,  ...,  0.0117, -0.0151,  0.0355],\n",
            "        [-0.0213, -0.0174, -0.0356,  ..., -0.0120, -0.0299,  0.0119],\n",
            "        [ 0.0110, -0.0246, -0.0125,  ..., -0.0129,  0.0082, -0.0330]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
            "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
            "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
            "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izs5_ErBw7-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qbzE2XFwcsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG6M_LDjwjv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e7d3289a-3a74-4ccd-ef27-73e0a85e1c41"
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0207,  0.0028, -0.0034,  ..., -0.0145, -0.0312, -0.0174],\n",
            "        [ 0.0129,  0.0149,  0.0335,  ...,  0.0240,  0.0066, -0.0346],\n",
            "        [ 0.0346,  0.0130,  0.0321,  ...,  0.0087,  0.0297,  0.0203],\n",
            "        ...,\n",
            "        [-0.0032,  0.0189,  0.0192,  ...,  0.0117, -0.0151,  0.0355],\n",
            "        [-0.0213, -0.0174, -0.0356,  ..., -0.0120, -0.0299,  0.0119],\n",
            "        [ 0.0110, -0.0246, -0.0125,  ..., -0.0129,  0.0082, -0.0330]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI72dFv9xsYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5da6f200-d74e-4572-9e09-4d6b5f4d880c"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 10\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    \n",
        "    ab=0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "      \n",
        "        \n",
        "    else:\n",
        "      \n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.929735808865602\n",
            "Training loss: 0.8610775168580033\n",
            "Training loss: 0.5216757252113398\n",
            "Training loss: 0.4287124993259719\n",
            "Training loss: 0.38609006908783783\n",
            "Training loss: 0.3594066732124225\n",
            "Training loss: 0.34055899210703144\n",
            "Training loss: 0.3256065608071747\n",
            "Training loss: 0.31278512757946686\n",
            "Training loss: 0.3022069237522606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AXSaZn2T4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dFCOkVP2pDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "70aa5048-4427-4df8-8b2a-08b9f5d28b1e"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}